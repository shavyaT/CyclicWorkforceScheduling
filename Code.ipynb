{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJd2NmDjw2eK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvCLF5L-w2eM"
      },
      "source": [
        "# Parsing and Structuring Schedule Data from Text Files\n",
        "#### Extracting and organizing the schedule-related information from multiple text files, including schedule length, employee count, shift details, and constraints and combines the parsed data into a Pandas DataFrame for easy analysis and saves the results as a CSV file for further use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXhQFl79w2eN"
      },
      "outputs": [],
      "source": [
        "# Function to parse a single file\n",
        "def parse_file(file_content):\n",
        "    try:\n",
        "        lines = [line.decode('utf-8').strip() for line in file_content if line.strip()]\n",
        "        data = {}\n",
        "        i = 0\n",
        "\n",
        "        while i < len(lines):\n",
        "            line = lines[i]\n",
        "\n",
        "            if \"Length of the schedule\" in line:\n",
        "                i += 1\n",
        "                data[\"schedule_length\"] = int(lines[i])\n",
        "            elif \"Number of Employees\" in line:\n",
        "                i += 1\n",
        "                data[\"num_employees\"] = int(lines[i])\n",
        "            elif \"Number of Shifts\" in line:\n",
        "                i += 1\n",
        "                # Check if the key exists before accessing\n",
        "                if i < len(lines):\n",
        "                    data[\"num_shifts\"] = int(lines[i])\n",
        "            elif \"# Temporal Requirements Matrix\" in line:\n",
        "                matrix = []\n",
        "                for _ in range(data.get(\"num_shifts\", 0)):  # Safe access\n",
        "                    i += 1\n",
        "                    if i < len(lines):\n",
        "                        row = list(map(int, lines[i].split()))\n",
        "                        matrix.append(row)\n",
        "                data[\"temporal_requirements\"] = matrix\n",
        "            elif \"#ShiftName\" in line:\n",
        "                shift_info = []\n",
        "                for _ in range(data.get(\"num_shifts\", 0)):  # Safe access\n",
        "                    i += 1\n",
        "                    if i < len(lines):\n",
        "                        tokens = lines[i].split()\n",
        "                        shift_info.append(tokens)\n",
        "                data[\"shift_info\"] = shift_info\n",
        "            elif \"# Minimum and maximum length of days-off blocks\" in line:\n",
        "                i += 1\n",
        "                if i < len(lines):\n",
        "                    tokens = list(map(int, lines[i].split()))\n",
        "                    data[\"days_off_min\"], data[\"days_off_max\"] = tokens\n",
        "            elif \"# Minimum and maximum length of work blocks\" in line:\n",
        "                i += 1\n",
        "                if i < len(lines):\n",
        "                    tokens = list(map(int, lines[i].split()))\n",
        "                    data[\"work_blocks_min\"], data[\"work_blocks_max\"] = tokens\n",
        "            elif \"# Number of not allowed shift sequences\" in line:\n",
        "                i += 1\n",
        "                if i < len(lines):\n",
        "                    tokens = list(map(int, lines[i].split()))\n",
        "                    data[\"nr_seq_2\"], data[\"nr_seq_3\"] = tokens\n",
        "            elif \"# Not allowed shift sequences\" in line:\n",
        "                not_allowed = []\n",
        "                for _ in range(data.get(\"nr_seq_2\", 0)):  # Safe access\n",
        "                    i += 1\n",
        "                    if i < len(lines):\n",
        "                        not_allowed.append(lines[i].split())\n",
        "                for _ in range(data.get(\"nr_seq_3\", 0)):  # Safe access\n",
        "                    i += 1\n",
        "                    if i < len(lines):\n",
        "                        not_allowed.append(lines[i].split())\n",
        "                data[\"not_allowed_sequences\"] = not_allowed\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing file {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Parse all files in the folder\n",
        "all_data = []\n",
        "\n",
        "with zipfile.ZipFile('/content/data.zip') as z:\n",
        "    for full_path in z.namelist():\n",
        "        if full_path.endswith(\".txt\"):\n",
        "            filename = os.path.basename(full_path)\n",
        "            with z.open(full_path) as file_content:\n",
        "                parsed_data = parse_file(file_content)\n",
        "                if parsed_data:\n",
        "                    all_data.append({\n",
        "                        \"filename\": filename,\n",
        "                        \"parsed_data\": parsed_data\n",
        "                    })\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "        \"filename\": item[\"filename\"],\n",
        "        \"schedule_length\": item[\"parsed_data\"].get(\"schedule_length\", None),\n",
        "        \"num_employees\": item[\"parsed_data\"].get(\"num_employees\", None),\n",
        "        \"num_shifts\": item[\"parsed_data\"].get(\"num_shifts\", None),\n",
        "        \"temporal_requirements\": item[\"parsed_data\"].get(\"temporal_requirements\", None),\n",
        "        \"shift_info\": item[\"parsed_data\"].get(\"shift_info\", None),\n",
        "        \"days_off_min\": item[\"parsed_data\"].get(\"days_off_min\", None),\n",
        "        \"days_off_max\": item[\"parsed_data\"].get(\"days_off_max\", None),\n",
        "        \"work_blocks_min\": item[\"parsed_data\"].get(\"work_blocks_min\", None),\n",
        "        \"work_blocks_max\": item[\"parsed_data\"].get(\"work_blocks_max\", None),\n",
        "        \"nr_seq_2\": item[\"parsed_data\"].get(\"nr_seq_2\", None),\n",
        "        \"nr_seq_3\": item[\"parsed_data\"].get(\"nr_seq_3\", None),\n",
        "        \"not_allowed_sequences\": item[\"parsed_data\"].get(\"not_allowed_sequences\", None)\n",
        "    } for item in all_data\n",
        "])\n",
        "\n",
        "\n",
        "# Save the DataFrame to CSV\n",
        "df.to_csv('parsed_schedule_20_examples.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L85wtaTgw2eN"
      },
      "source": [
        "##  Exploration of Initialization and Weighting Strategies in Scheduling\n",
        "#### Exploring different initialization methods (random and greedy) and penalty weighting schemes for scheduling problems. Using a fixed heuristic of Min Conflict with Simulated Annealing (SA), it evaluates the impact of various strategies on conflict reduction. We are working with the first instance of the dataset for testing different initialization and weighting methods. Results are saved in CSV and text formats to analyze the performance across combinations.\n",
        "##### Weighted Method 1: 4 - temporal, 3 - off days, 2 - not allowed sequences, 1 - shift blocks and work blocks\n",
        "##### Weighted Method 2: 2 - temporal requirements and off days, 1 for rest\n",
        "##### Weighted Method 3: 1000 - hard constraints, 200 - moderate constraints, 10 - Soft constraints\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfjb_yrTw2eO",
        "outputId": "58ec1129-43a4-44e1-ea17-fa12957685e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to results_testing_with_SA.csv and results_testing_with_SA.txt.\n"
          ]
        }
      ],
      "source": [
        "# 1. PARSE FUNCTIONS\n",
        "\n",
        "def parse_temporal_requirements(temporal_requirements_str):\n",
        "    return eval(temporal_requirements_str)\n",
        "\n",
        "def parse_shift_info(shift_info_str):\n",
        "    shift_list = eval(shift_info_str)\n",
        "    return [\n",
        "        {\n",
        "            'shift_name': s[0],\n",
        "            'start': int(s[1]),\n",
        "            'length': int(s[2]),\n",
        "            'min_blocks': int(s[3]),\n",
        "            'max_blocks': int(s[4])\n",
        "        }\n",
        "        for s in shift_list\n",
        "    ]\n",
        "\n",
        "def parse_not_allowed_sequences(not_allowed_sequences_str):\n",
        "    return [tuple(pair) for pair in eval(not_allowed_sequences_str)]\n",
        "\n",
        "# 2. INITIALIZATION METHODS\n",
        "\n",
        "def generate_random_schedule(num_employees, schedule_length):\n",
        "    possible_shifts = ['D', 'A', 'N', '-']\n",
        "    schedule = {}\n",
        "    for emp_id in range(num_employees):\n",
        "        schedule[emp_id] = [random.choice(possible_shifts) for _ in range(schedule_length)]\n",
        "    return schedule\n",
        "\n",
        "def generate_greedy_schedule(row_data):\n",
        "    possible_shifts = ['D', 'A', 'N']  # ONLY the staffed shifts\n",
        "    num_employees = int(row_data[\"num_employees\"])\n",
        "    schedule_length = int(row_data[\"schedule_length\"])\n",
        "    temporal_requirements = parse_temporal_requirements(row_data[\"temporal_requirements\"])\n",
        "\n",
        "    # Start everyone as off '-'\n",
        "    schedule = {emp_id: ['-'] * schedule_length for emp_id in range(num_employees)}\n",
        "\n",
        "    for day in range(schedule_length):\n",
        "        # Sort the *staffed* shifts by required demand (descending)\n",
        "        shift_demand_order = sorted(\n",
        "            possible_shifts,\n",
        "            key=lambda sh: temporal_requirements[possible_shifts.index(sh)][day],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # Fill day with required number of employees for each shift\n",
        "        for shift in shift_demand_order:\n",
        "            employees_needed = temporal_requirements[possible_shifts.index(shift)][day]\n",
        "            # Sort employees by how many times they've had `shift` to distribute fairly\n",
        "            sorted_employees = sorted(schedule.items(), key=lambda x: x[1].count(shift))\n",
        "\n",
        "            assigned_count = 0\n",
        "            for emp_id, emp_sched in sorted_employees:\n",
        "                # If this employee is off (i.e. '-') on this day and we still need employees:\n",
        "                if emp_sched[day] == '-' and assigned_count < employees_needed:\n",
        "                    schedule[emp_id][day] = shift\n",
        "                    assigned_count += 1\n",
        "\n",
        "    return schedule\n",
        "\n",
        "# 3. CONFLICT EVALUATION\n",
        "\n",
        "def evaluate_conflicts(schedule, row_data, method=1):\n",
        "    # Parse the data\n",
        "    temporal_req = parse_temporal_requirements(row_data[\"temporal_requirements\"])\n",
        "    shift_defs = parse_shift_info(row_data[\"shift_info\"])\n",
        "    not_allowed_seq = parse_not_allowed_sequences(row_data[\"not_allowed_sequences\"])\n",
        "    nr_seq_2 = row_data[\"nr_seq_2\"]\n",
        "    nr_seq_3 = row_data[\"nr_seq_3\"]\n",
        "    schedule_len = row_data[\"schedule_length\"]\n",
        "\n",
        "    days_off_min = row_data[\"days_off_min\"]\n",
        "    days_off_max = row_data[\"days_off_max\"]\n",
        "    work_blocks_min = row_data[\"work_blocks_min\"]\n",
        "    work_blocks_max = row_data[\"work_blocks_max\"]\n",
        "\n",
        "    shift_block_limits = {\n",
        "        sd['shift_name']: (sd['min_blocks'], sd['max_blocks']) for sd in shift_defs\n",
        "    }\n",
        "\n",
        "    conflicts = 0\n",
        "\n",
        "    # Weights based on method\n",
        "    weights = {1: {\"temporal\": 4, \"off_days\": 3, \"sequences\": 2, \"blocks\": 1},\n",
        "               2: {\"temporal\": 2, \"off_days\": 2, \"sequences\": 1, \"blocks\": 1},\n",
        "               3: {\"temporal\": 1000, \"off_days\": 200, \"sequences\": 1000, \"blocks\": 10}}[method]\n",
        "\n",
        "    # Temporal requirements\n",
        "    for day in range(schedule_len):\n",
        "        shift_count = defaultdict(int)\n",
        "        for emp_schedule in schedule.values():\n",
        "            shift = emp_schedule[day]\n",
        "            if shift != '-':\n",
        "                shift_count[shift] += 1\n",
        "\n",
        "        for shift_id, shift_info in enumerate(shift_defs):\n",
        "            shift_name = shift_info['shift_name']\n",
        "            assigned = shift_count.get(shift_name, 0)\n",
        "            required = temporal_req[shift_id][day]\n",
        "            diff = abs(assigned - required)\n",
        "            conflicts += weights[\"temporal\"] * diff\n",
        "\n",
        "    # Employee-specific constraints\n",
        "    for emp_sched in schedule.values():\n",
        "        segments = []\n",
        "        curr_shift = emp_sched[0]\n",
        "        curr_len = 1\n",
        "        for d in range(1, len(emp_sched)):\n",
        "            if emp_sched[d] == curr_shift:\n",
        "                curr_len += 1\n",
        "            else:\n",
        "                segments.append((curr_shift, curr_len))\n",
        "                curr_shift = emp_sched[d]\n",
        "                curr_len = 1\n",
        "        segments.append((curr_shift, curr_len))\n",
        "\n",
        "        for seg_type, seg_len in segments:\n",
        "            if seg_type == '-':\n",
        "                if seg_len < days_off_min or seg_len > days_off_max:\n",
        "                    conflicts += weights[\"off_days\"]\n",
        "            else:\n",
        "                if seg_type in shift_block_limits:\n",
        "                    min_b, max_b = shift_block_limits[seg_type]\n",
        "                    if seg_len < min_b or seg_len > max_b:\n",
        "                        conflicts += weights[\"blocks\"]\n",
        "\n",
        "        # Not allowed sequences\n",
        "        for day in range(len(emp_sched)):\n",
        "            if day > 0:\n",
        "                prev_shift = emp_sched[day - 1]\n",
        "                curr_shift = emp_sched[day]\n",
        "                if nr_seq_2 > 0 and (prev_shift, curr_shift) in not_allowed_seq:\n",
        "                    conflicts += weights[\"sequences\"]\n",
        "                if day > 1 and nr_seq_3 > 0:\n",
        "                    prev_prev = emp_sched[day - 2]\n",
        "                    if (prev_prev, prev_shift, curr_shift) in not_allowed_seq:\n",
        "                        conflicts += weights[\"sequences\"]\n",
        "\n",
        "    return conflicts\n",
        "\n",
        "# 4. LOCAL SEARCH AND SIMULATED ANNEALING\n",
        "\n",
        "def min_conflicts_step(schedule, row_data, method=1):\n",
        "    possible_shifts = ['D', 'A', 'N', '-']\n",
        "    new_schedule = {emp: days[:] for emp, days in schedule.items()}  # deep copy\n",
        "    schedule_length = len(next(iter(new_schedule.values())))\n",
        "\n",
        "    emp_id = random.choice(list(new_schedule.keys()))\n",
        "    day = random.randint(0, schedule_length - 1)\n",
        "    original_shift = new_schedule[emp_id][day]\n",
        "    best_shift = original_shift\n",
        "    min_conf = float('inf')\n",
        "\n",
        "    for candidate_shift in possible_shifts:\n",
        "        new_schedule[emp_id][day] = candidate_shift\n",
        "        c = evaluate_conflicts(new_schedule, row_data, method=method)\n",
        "        if c < min_conf:\n",
        "            min_conf = c\n",
        "            best_shift = candidate_shift\n",
        "        new_schedule[emp_id][day] = original_shift\n",
        "\n",
        "    new_schedule[emp_id][day] = best_shift\n",
        "    return new_schedule\n",
        "\n",
        "def simulated_annealing(schedule, row_data, method=1, max_evaluations=10000, temperature=1000, cooling_rate=0.995):\n",
        "    current_solution = schedule\n",
        "    current_cost = evaluate_conflicts(current_solution, row_data, method=method)\n",
        "    best_solution = current_solution\n",
        "    best_cost = current_cost\n",
        "\n",
        "    evaluations = 0\n",
        "\n",
        "    while evaluations < max_evaluations and temperature > 1:\n",
        "        neighbor = min_conflicts_step(current_solution, row_data, method=method)\n",
        "        neighbor_cost = evaluate_conflicts(neighbor, row_data, method=method)\n",
        "\n",
        "        cost_diff = current_cost - neighbor_cost\n",
        "        if cost_diff > 0 or random.random() < math.exp(cost_diff / temperature):\n",
        "            current_solution = neighbor\n",
        "            current_cost = neighbor_cost\n",
        "            if current_cost < best_cost:\n",
        "                best_solution = current_solution\n",
        "                best_cost = current_cost\n",
        "\n",
        "        temperature *= cooling_rate\n",
        "        evaluations += 1\n",
        "\n",
        "    return best_solution, best_cost\n",
        "\n",
        "# 5. RUN ALL COMBINATIONS & SAVE RESULTS\n",
        "\n",
        "def run_scheduling(input_csv_path, output_csv_path=\"results_testing_with_SA.csv\",\n",
        "                   output_txt_path=\"results_testing_with_SA.txt\"):\n",
        "    data = pd.read_csv(input_csv_path)\n",
        "    results = []\n",
        "\n",
        "    init_modes = [\"RANDOM\", \"GREEDY\"]\n",
        "    weight_methods = [1, 2, 3]\n",
        "\n",
        "    with open(output_txt_path, \"w\") as txt_file:\n",
        "        for idx, row in data.iterrows():\n",
        "            row_data = {\n",
        "                \"temporal_requirements\": row[\"temporal_requirements\"],\n",
        "                \"shift_info\": row[\"shift_info\"],\n",
        "                \"days_off_min\": row[\"days_off_min\"],\n",
        "                \"days_off_max\": row[\"days_off_max\"],\n",
        "                \"work_blocks_min\": row[\"work_blocks_min\"],\n",
        "                \"work_blocks_max\": row[\"work_blocks_max\"],\n",
        "                \"not_allowed_sequences\": row[\"not_allowed_sequences\"],\n",
        "                \"nr_seq_2\": row[\"nr_seq_2\"],\n",
        "                \"nr_seq_3\": row[\"nr_seq_3\"],\n",
        "                \"schedule_length\": row[\"schedule_length\"],\n",
        "                \"num_employees\": row[\"num_employees\"]\n",
        "            }\n",
        "\n",
        "            for init_mode in init_modes:\n",
        "                for method in weight_methods:\n",
        "                    if init_mode == \"RANDOM\":\n",
        "                        schedule_init = generate_random_schedule(\n",
        "                            num_employees=row_data[\"num_employees\"],\n",
        "                            schedule_length=row_data[\"schedule_length\"]\n",
        "                        )\n",
        "                    else:\n",
        "                        schedule_init = generate_greedy_schedule(row_data)\n",
        "\n",
        "                    start_time = time.time()\n",
        "                    best_solution, best_cost = simulated_annealing(\n",
        "                        schedule_init, row_data, method=method\n",
        "                    )\n",
        "                    elapsed = time.time() - start_time\n",
        "\n",
        "                    formatted_schedule = \"\\n\".join(\n",
        "                        [f\"Emp {k}: {' '.join(v)}\" for k, v in best_solution.items()]\n",
        "                    )\n",
        "                    results.append({\n",
        "                        \"row_index\": idx,\n",
        "                        \"init_mode\": init_mode,\n",
        "                        \"method\": method,\n",
        "                        \"time_in_sec\": round(elapsed, 4),\n",
        "                        \"conflicts\": best_cost,\n",
        "                        \"schedule\": formatted_schedule\n",
        "                    })\n",
        "\n",
        "                    # Write to text file\n",
        "                    txt_file.write(f\"Row: {idx}, Init Mode: {init_mode}, Method: {method}\\n\")\n",
        "                    txt_file.write(f\"Time (s): {round(elapsed, 4)}, Conflicts: {best_cost}\\n\")\n",
        "                    txt_file.write(f\"Schedule:\\n{formatted_schedule}\\n\")\n",
        "                    txt_file.write(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "            if idx > 0:\n",
        "                break\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Results saved to {output_csv_path} and {output_txt_path}.\")\n",
        "\n",
        "# 6. MAIN ENTRY POINT\n",
        "\n",
        "run_scheduling(input_csv_path = \"/content/parsed_schedule_20_examples.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3xREQSRw2eP"
      },
      "source": [
        "## Comparison of Heuristics for Scheduling Optimization\n",
        "#### Building on insights from the first code, this implementation fixes the weighting method (Method 2) and uses greedy initialization. It now compares three heuristic approaches: Min Conflict with Simulated Annealing, Min Conflict with Tabu Search, and Constraint-Guided Simulated Annealing—to determine the most effective method. Results are saved for performance analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2Zfe2uCw2eQ",
        "outputId": "bfef5592-019d-430e-a7eb-646978f6bfa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to results_method_comparison.csv and results_method_comparison.txt.\n"
          ]
        }
      ],
      "source": [
        "# 1. PARSE FUNCTIONS\n",
        "\n",
        "def parse_temporal_requirements(temporal_requirements_str):\n",
        "    try:\n",
        "        return eval(temporal_requirements_str)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Invalid temporal_requirements format: {e}\")\n",
        "\n",
        "def parse_shift_info(shift_info_str):\n",
        "    try:\n",
        "        shift_list = eval(shift_info_str)\n",
        "        return [\n",
        "            {\n",
        "                'shift_name': s[0],\n",
        "                'start': int(s[1]),\n",
        "                'length': int(s[2]),\n",
        "                'min_blocks': int(s[3]),\n",
        "                'max_blocks': int(s[4])\n",
        "            }\n",
        "            for s in shift_list\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Invalid shift_info format: {e}\")\n",
        "\n",
        "def parse_not_allowed_sequences(not_allowed_sequences_str):\n",
        "    try:\n",
        "        return [tuple(seq) for seq in eval(not_allowed_sequences_str)]\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Invalid not_allowed_sequences format: {e}\")\n",
        "\n",
        "# 2. VALID SHIFTS\n",
        "\n",
        "def get_valid_shifts(shift_defs):\n",
        "    return [shift['shift_name'] for shift in shift_defs]\n",
        "\n",
        "def get_possible_shifts_with_off_day(shift_defs):\n",
        "    return [shift['shift_name'] for shift in shift_defs] + ['-']\n",
        "\n",
        "# 3. GREEDY INITIALIZATION\n",
        "\n",
        "def generate_greedy_schedule(row_data):\n",
        "    temporal_requirements = parse_temporal_requirements(row_data[\"temporal_requirements\"])\n",
        "    shift_defs = parse_shift_info(row_data[\"shift_info\"])\n",
        "    schedule_length = int(row_data[\"schedule_length\"])\n",
        "    num_employees = int(row_data[\"num_employees\"])\n",
        "\n",
        "    # Extract valid shifts\n",
        "    valid_shifts = get_valid_shifts(shift_defs)\n",
        "\n",
        "    # Validate temporal requirements\n",
        "    if len(temporal_requirements) != len(valid_shifts):\n",
        "        raise ValueError(\n",
        "            f\"Mismatch: temporal_requirements has {len(temporal_requirements)} shifts, \"\n",
        "            f\"but expected {len(valid_shifts)} shifts based on shift_info.\"\n",
        "        )\n",
        "    if any(len(req) != schedule_length for req in temporal_requirements):\n",
        "        raise ValueError(\n",
        "            f\"Temporal requirements sublists must have length {schedule_length}. \"\n",
        "            f\"Found {[len(req) for req in temporal_requirements]}.\"\n",
        "        )\n",
        "\n",
        "    schedule = {emp_id: ['-'] * schedule_length for emp_id in range(num_employees)}\n",
        "\n",
        "    for day in range(schedule_length):\n",
        "        # Sort shifts by demand descending\n",
        "        shift_demand_order = sorted(\n",
        "            valid_shifts,\n",
        "            key=lambda sh: temporal_requirements[valid_shifts.index(sh)][day],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        for shift in shift_demand_order:\n",
        "            employees_needed = temporal_requirements[valid_shifts.index(shift)][day]\n",
        "            if employees_needed <= 0:\n",
        "                continue  # Skip if no employees needed for this shift on this day\n",
        "\n",
        "            # Sort employees by how many times they've had this shift to distribute fairly\n",
        "            sorted_employees = sorted(schedule.items(), key=lambda x: x[1].count(shift))\n",
        "\n",
        "            assigned = 0\n",
        "            for emp_id, emp_schedule in sorted_employees:\n",
        "                if schedule[emp_id][day] == '-' and assigned < employees_needed:\n",
        "                    schedule[emp_id][day] = shift\n",
        "                    assigned += 1\n",
        "                if assigned >= employees_needed:\n",
        "                    break  # Move to the next shift after fulfilling the demand\n",
        "\n",
        "    return schedule\n",
        "\n",
        "# 4. CONFLICT EVALUATION\n",
        "\n",
        "def evaluate_conflicts(schedule, row_data):\n",
        "    temporal_req = parse_temporal_requirements(row_data[\"temporal_requirements\"])\n",
        "    shift_defs = parse_shift_info(row_data[\"shift_info\"])\n",
        "    not_allowed_seq = parse_not_allowed_sequences(row_data[\"not_allowed_sequences\"])\n",
        "    schedule_len = int(row_data[\"schedule_length\"])\n",
        "\n",
        "    days_off_min = int(row_data[\"days_off_min\"])\n",
        "    days_off_max = int(row_data[\"days_off_max\"])\n",
        "\n",
        "    conflicts = 0\n",
        "    weights = {\"temporal\": 2, \"off_days\": 2, \"sequences\": 1, \"blocks\": 1}\n",
        "\n",
        "    # Extract shift names\n",
        "    valid_shifts = get_valid_shifts(shift_defs)\n",
        "\n",
        "    # Create a mapping for shift_name to index for faster access\n",
        "    shift_name_to_index = {shift['shift_name']: idx for idx, shift in enumerate(shift_defs)}\n",
        "\n",
        "    # (1) Temporal Requirements\n",
        "    for day in range(schedule_len):\n",
        "        shift_count = defaultdict(int)\n",
        "        for emp_schedule in schedule.values():\n",
        "            shift = emp_schedule[day]\n",
        "            if shift in valid_shifts:\n",
        "                shift_count[shift] += 1\n",
        "\n",
        "        for shift in valid_shifts:\n",
        "            assigned = shift_count.get(shift, 0)\n",
        "            required = temporal_req[shift_name_to_index[shift]][day]\n",
        "            diff = abs(assigned - required)\n",
        "            conflicts += weights[\"temporal\"] * diff\n",
        "\n",
        "    # (2) Employee-specific constraints\n",
        "    for emp_sched in schedule.values():\n",
        "        segments = []\n",
        "        curr_shift = emp_sched[0]\n",
        "        curr_len = 1\n",
        "\n",
        "        # Identify consecutive segments\n",
        "        for d in range(1, schedule_len):\n",
        "            if emp_sched[d] == curr_shift:\n",
        "                curr_len += 1\n",
        "            else:\n",
        "                segments.append((curr_shift, curr_len))\n",
        "                curr_shift = emp_sched[d]\n",
        "                curr_len = 1\n",
        "        segments.append((curr_shift, curr_len))  # Add the last segment\n",
        "\n",
        "        # Check days-off constraints and shift/work block constraints\n",
        "        for seg_type, seg_len in segments:\n",
        "            if seg_type == '-':\n",
        "                if seg_len < days_off_min:\n",
        "                    conflicts += weights[\"off_days\"] * (days_off_min - seg_len)\n",
        "                elif seg_len > days_off_max:\n",
        "                    conflicts += weights[\"off_days\"] * (seg_len - days_off_max)\n",
        "            elif seg_type in valid_shifts:\n",
        "                shift_def = shift_defs[shift_name_to_index[seg_type]]\n",
        "                min_b = shift_def['min_blocks']\n",
        "                max_b = shift_def['max_blocks']\n",
        "                if seg_len < min_b:\n",
        "                    conflicts += weights[\"blocks\"] * (min_b - seg_len)\n",
        "                elif seg_len > max_b:\n",
        "                    conflicts += weights[\"blocks\"] * (seg_len - max_b)\n",
        "\n",
        "        # Check not allowed sequences\n",
        "        for day in range(schedule_len):\n",
        "            if day > 0:\n",
        "                prev_shift = emp_sched[day - 1]\n",
        "                curr_shift = emp_sched[day]\n",
        "                if (prev_shift, curr_shift) in not_allowed_seq:\n",
        "                    conflicts += weights[\"sequences\"]\n",
        "            if day > 1:\n",
        "                prev_prev_shift = emp_sched[day - 2]\n",
        "                prev_shift = emp_sched[day - 1]\n",
        "                curr_shift = emp_sched[day]\n",
        "                if (prev_prev_shift, prev_shift, curr_shift) in not_allowed_seq:\n",
        "                    conflicts += weights[\"sequences\"]\n",
        "\n",
        "    return conflicts\n",
        "\n",
        "# 5. TABU SEARCH\n",
        "\n",
        "def generate_neighbors(schedule, row_data):\n",
        "    shift_defs = parse_shift_info(row_data[\"shift_info\"])\n",
        "    valid_shifts = get_valid_shifts(shift_defs)\n",
        "    possible_shifts = valid_shifts + ['-']\n",
        "    neighbors = []\n",
        "    for _ in range(5):  # Generate 5 neighbors\n",
        "        neighbor = {emp: days[:] for emp, days in schedule.items()}  # Deep copy\n",
        "        emp_id = random.choice(list(neighbor.keys()))\n",
        "        day = random.randint(0, len(neighbor[emp_id]) - 1)\n",
        "        current_shift = neighbor[emp_id][day]\n",
        "        possible_changes = [s for s in possible_shifts if s != current_shift]\n",
        "        new_shift = random.choice(possible_changes)\n",
        "        neighbor[emp_id][day] = new_shift\n",
        "        move = (emp_id, day, new_shift)\n",
        "        neighbors.append((neighbor, move))\n",
        "    return neighbors\n",
        "\n",
        "def tabu_search(schedule, row_data, max_iterations=1000, tabu_tenure=10):\n",
        "    current_solution = schedule\n",
        "    best_solution = schedule\n",
        "    best_cost = evaluate_conflicts(best_solution, row_data)\n",
        "\n",
        "    tabu_list = []\n",
        "    max_tabu_size = tabu_tenure\n",
        "    iterations = 0\n",
        "\n",
        "    while iterations < max_iterations:\n",
        "        neighbors = generate_neighbors(current_solution, row_data)\n",
        "        best_neighbor = None\n",
        "        best_neighbor_cost = float('inf')\n",
        "        best_move = None\n",
        "\n",
        "        for neighbor, move in neighbors:\n",
        "            if move not in tabu_list:\n",
        "                neighbor_cost = evaluate_conflicts(neighbor, row_data)\n",
        "                if neighbor_cost < best_neighbor_cost:\n",
        "                    best_neighbor = neighbor\n",
        "                    best_neighbor_cost = neighbor_cost\n",
        "                    best_move = move\n",
        "\n",
        "        if best_neighbor is None:\n",
        "            break  # No valid neighbors\n",
        "\n",
        "        if best_neighbor_cost < best_cost:\n",
        "            best_solution = best_neighbor\n",
        "            best_cost = best_neighbor_cost\n",
        "\n",
        "        current_solution = best_neighbor\n",
        "        tabu_list.append(best_move)\n",
        "        if len(tabu_list) > max_tabu_size:\n",
        "            tabu_list.pop(0)\n",
        "        iterations += 1\n",
        "\n",
        "    return best_solution, best_cost\n",
        "\n",
        "# 6. SIMULATED ANNEALING WITH CONSTRAINT-GUIDED STEP\n",
        "\n",
        "def constraint_guided_step(schedule, row_data):\n",
        "    shift_defs = parse_shift_info(row_data[\"shift_info\"])\n",
        "    valid_shifts = get_valid_shifts(shift_defs)\n",
        "    possible_shifts = valid_shifts + ['-']\n",
        "    new_schedule = {emp: days[:] for emp, days in schedule.items()}\n",
        "    emp_id = random.choice(list(new_schedule.keys()))\n",
        "    day = random.randint(0, len(new_schedule[emp_id]) - 1)\n",
        "    original_shift = new_schedule[emp_id][day]\n",
        "    best_shift = original_shift\n",
        "    min_violations = float('inf')\n",
        "\n",
        "    for shift in possible_shifts:\n",
        "        new_schedule[emp_id][day] = shift\n",
        "        violations = evaluate_conflicts(new_schedule, row_data)\n",
        "        if violations < min_violations:\n",
        "            min_violations = violations\n",
        "            best_shift = shift\n",
        "        new_schedule[emp_id][day] = original_shift  # Reset for next iteration\n",
        "\n",
        "    new_schedule[emp_id][day] = best_shift\n",
        "    return new_schedule\n",
        "\n",
        "def simulated_annealing(schedule, row_data, max_evaluations=10000, temperature=1000, cooling_rate=0.995):\n",
        "    current_solution = schedule\n",
        "    best_solution = schedule\n",
        "    best_cost = evaluate_conflicts(best_solution, row_data)\n",
        "    evaluations = 0\n",
        "\n",
        "    while evaluations < max_evaluations and temperature > 1:\n",
        "        neighbor = constraint_guided_step(current_solution, row_data)\n",
        "        neighbor_cost = evaluate_conflicts(neighbor, row_data)\n",
        "        cost_diff = best_cost - neighbor_cost\n",
        "\n",
        "        if cost_diff > 0 or random.random() < math.exp(cost_diff / temperature):\n",
        "            current_solution = neighbor\n",
        "            if neighbor_cost < best_cost:\n",
        "                best_solution = neighbor\n",
        "                best_cost = neighbor_cost\n",
        "\n",
        "        temperature *= cooling_rate\n",
        "        evaluations += 1\n",
        "\n",
        "    return best_solution, best_cost\n",
        "\n",
        "# 7. RUN COMPARISONS AND SAVE RESULTS\n",
        "\n",
        "def run_scheduling(input_csv_path, output_csv_path=\"results_method_comparison.csv\",\n",
        "                   output_txt_path=\"results_method_comparison.txt\"):\n",
        "    try:\n",
        "        data = pd.read_csv(input_csv_path)\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"Error reading input CSV file: {e}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    with open(output_txt_path, \"w\") as txt_file:\n",
        "        for idx, row in data.iterrows():\n",
        "            try:\n",
        "                row_data = {\n",
        "                    \"temporal_requirements\": row[\"temporal_requirements\"],\n",
        "                    \"shift_info\": row[\"shift_info\"],\n",
        "                    \"days_off_min\": row[\"days_off_min\"],\n",
        "                    \"days_off_max\": row[\"days_off_max\"],\n",
        "                    \"schedule_length\": row[\"schedule_length\"],\n",
        "                    \"num_employees\": row[\"num_employees\"],\n",
        "                    \"not_allowed_sequences\": row[\"not_allowed_sequences\"]\n",
        "                }\n",
        "\n",
        "                # Greedy initialization\n",
        "                initial_schedule = generate_greedy_schedule(row_data)\n",
        "\n",
        "                # Run SA + min conflict\n",
        "                start_time = time.time()\n",
        "                sa_schedule, sa_cost = simulated_annealing(initial_schedule, row_data)\n",
        "                sa_time = time.time() - start_time\n",
        "\n",
        "                # Run Tabu + min conflict\n",
        "                start_time = time.time()\n",
        "                tabu_schedule, tabu_cost = tabu_search(initial_schedule, row_data)\n",
        "                tabu_time = time.time() - start_time\n",
        "\n",
        "                # Run Constraint-Guided + SA\n",
        "                start_time = time.time()\n",
        "                cg_schedule, cg_cost = simulated_annealing(initial_schedule, row_data)\n",
        "                cg_time = time.time() - start_time\n",
        "\n",
        "                # Save results for each method\n",
        "                for method, cost, time_taken, schedule in [(\"SA + Min Conflict\", sa_cost, sa_time, sa_schedule),\n",
        "                                                           (\"Tabu + Min Conflict\", tabu_cost, tabu_time, tabu_schedule),\n",
        "                                                           (\"Constraint-Guided + SA\", cg_cost, cg_time, cg_schedule)]:\n",
        "                    formatted_schedule = \"\\n\".join([f\"Emp {k}: {' '.join(v)}\" for k, v in schedule.items()])\n",
        "                    results.append({\n",
        "                        \"instance_name\": row[\"filename\"],\n",
        "                        \"method\": method,\n",
        "                        \"time_in_sec\": round(time_taken, 4),\n",
        "                        \"conflicts\": cost,\n",
        "                        \"best_schedule\": formatted_schedule\n",
        "                    })\n",
        "\n",
        "                    txt_file.write(f\"Instance: {row['filename']}, Method: {method}\\n\")\n",
        "                    txt_file.write(f\"Time: {round(time_taken, 4)} sec, Conflicts: {cost}\\n\")\n",
        "                    txt_file.write(f\"Best Schedule:\\n{formatted_schedule}\\n\")\n",
        "                    txt_file.write(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row {idx}: {e}\")\n",
        "                txt_file.write(f\"Error processing row {idx}: {e}\\n\")\n",
        "                txt_file.write(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "    # Save results to CSV\n",
        "    try:\n",
        "        results_df = pd.DataFrame(results)\n",
        "        results_df.to_csv(output_csv_path, index=False)\n",
        "        print(f\"Results saved to {output_csv_path} and {output_txt_path}.\")\n",
        "    except Exception as e:\n",
        "        raise IOError(f\"Error saving results: {e}\")\n",
        "\n",
        "# 8. MAIN FUNCTION\n",
        "\n",
        "run_scheduling(input_csv_path=\"/content/parsed_schedule_20_examples.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}